---
description: >-
  The original research proposal provided to the Chan-Zuckerberg initiative to
  secure funding for the project
---

# Research Proposal

Optical microscopy is the workhorse of biology. Its spatial resolution is limited primarily by diffraction. Its temporal resolution is limited by the sensor-response time. Its spectral resolution trades off either temporal (e.g., capturing one spectral-channel at a time) or spatial resolution (e.g., multi-spectral filters covering multiple sensor-pixels). Currently, there is no optical-microscopy modality that can combine high spatial, temporal and spectral resolutions. This team will combine a lossless Diffractive-Filter Array (DFA) with an Event-Based-Image Sensor (EBIS) resulting in sub-cellular spatial, sub-millisecond temporal, and sub-10nm spectral resolutions. Distinguishing space-time events via their spectra will enable imaging of large numbers of fluorophores with almost overlapping spectra. Since different kinds of individual sub-structures (e.g., molecular complexes, organelles or microbial cells) could be labeled with unique fluorophores, the proposed approach would be highly beneficial in deconstructing, and understanding organization at many levels within biological systems. The EBIS responds to changes in log intensity. The DFA operates on the incident electromagnetic field, whereby the diffracted-intensity distribution acquired by the sensor pixels encode both spatial location and local-spectral content. As a result, the EBIS augmented by the DFA responds not only to moving edges, but also to transients in spectrum. This straightforward modification of a commercial EBIS converts it into a spatio-spectral event-based sensor, which is the key innovation in this proposal. Applying deep-learning methods to 4D (x, y, l, t) event streams, neuromorphic inferencing of myriad forms of biological data (from firing of action potentials to photosynthetic energy pathways) may be achieved.
